{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4297891",
   "metadata": {},
   "source": [
    "# 4 Generating the Bank for the MicroTasks\n",
    "\n",
    "To generate the bank for the microtasks I will use an API for an LLM.\n",
    "The output will be two questions for each core course of each programme.\n",
    "\n",
    "Basically I will create the perfect prompt that will use the columns of the df_courses to generate the microstasks. \n",
    "\n",
    "We use two prompts: broad + disambiguaition (Kenneth Style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a37def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "#!pip install --upgrade openai\n",
    "import os, re\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # optional progress bar, pip install tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6274530",
   "metadata": {},
   "source": [
    "## 1 Load the data and filter for max 2 courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209c821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the courses tasks dataframe is: (36, 21)\n",
      "After keeping only first two courses from each programme the shape is: (28, 21)\n"
     ]
    }
   ],
   "source": [
    "# load the csv file about the courses forwhih we have to gen the tasks\n",
    "silver = Path(\"../data_programmes_courses/silver\")\n",
    "\n",
    "df_courses_tasks = pd.read_csv(silver / \"df_courses_tasks_silver.csv\", encoding=\"utf-8-sig\")\n",
    "print(\"The shape of the courses tasks dataframe is:\", df_courses_tasks.shape)\n",
    "\n",
    "# keep only first two courses from each programme\n",
    "df_courses_tasks = df_courses_tasks.groupby(\"programme_title\").head(2).reset_index(drop=True)\n",
    "print(\"After keeping only first two courses from each programme the shape is:\", df_courses_tasks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1387546c",
   "metadata": {},
   "source": [
    "## 2. Set up OpenAI client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7c36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_path = Path(\"../data_bank_microtasks\") / \"api_key.txt\"\n",
    "\n",
    "# Read the key and strip spaces and newlines\n",
    "api_key = key_path.read_text(encoding=\"utf8\").strip()\n",
    "\n",
    "# Create the client using this key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "models = client.models.list()\n",
    "#for m in models.data:\n",
    "#    print(m.id)\n",
    "\n",
    "model_gpt = \"gpt-4.1-mini\"  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf104b2",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Filtering the coding and math courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8750d78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses tagged as python:\n",
      "['Introduction to Programming' 'Introduction to Business Analytics'\n",
      " 'Computer Programming']\n",
      "\n",
      "Courses tagged as math for puzzle:\n",
      "['Calculus and Analysis I' 'Calculus 1' 'Logic and Sets for CS'\n",
      " 'Quantitative Research Methods I' 'Basic Concepts in Mathematics'\n",
      " 'Single Variable Calculus']\n"
     ]
    }
   ],
   "source": [
    "# here we define manually which courses should count as python coding courses\n",
    "# we can extend this set later if we want to add more courses\n",
    "CODING_COURSES_PYTHON = {\n",
    "    \"Introduction to Programming\",\n",
    "    \"Computer Programming\",\n",
    "    \"Introduction to Business Analytics\",  # we can remove this if it does not use python in practice\n",
    "}\n",
    "\n",
    "# here we define which courses are math related for puzzle tasks\n",
    "MATH_PUZZLE_COURSES = {\n",
    "    \"Calculus and Analysis I\",\n",
    "    \"Calculus 1\",\n",
    "    \"Single Variable Calculus\",\n",
    "    \"Basic Concepts in Mathematics\",\n",
    "    \"Logic and Sets for CS\",\n",
    "    \"Quantitative Research Methods I\"\n",
    "}\n",
    "\n",
    "# here we add boolean flags to the dataframe\n",
    "df_courses_tasks[\"uses_python\"] = df_courses_tasks[\"course_name\"].isin(CODING_COURSES_PYTHON)\n",
    "df_courses_tasks[\"math_puzzle\"] = df_courses_tasks[\"course_name\"].isin(MATH_PUZZLE_COURSES)\n",
    "\n",
    "print(\"Courses tagged as python:\")\n",
    "print(df_courses_tasks.loc[df_courses_tasks[\"uses_python\"], \"course_name\"].unique())\n",
    "\n",
    "print(\"\\nCourses tagged as math for puzzle:\")\n",
    "print(df_courses_tasks.loc[df_courses_tasks[\"math_puzzle\"], \"course_name\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ddf8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def course_uses_python(row: pd.Series) -> bool:\n",
    "    \"\"\"\n",
    "    With this function we decide if a course should receive a codeorder challenge.\n",
    "    We use the manual flag uses_python that we added above.\n",
    "    \"\"\"\n",
    "    return bool(row.get(\"uses_python\", False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59136302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of programmes: 14\n",
      "First few programmes: ['Ancient Studies', 'Biomedical Sciences', 'Business Analytics', 'Communication and Information Studies', 'Computer Science']\n",
      "Sample course context:\n",
      "Programme: Literature and Society\n",
      "Course: Creative Writing I\n",
      "Objectives: Als je deze cursus hebt gevolgd kan je:\n",
      "basale narratieve structuren en schrijftechnieken op het gebied van onder meer stijl, plot, scènes en personages, zoals o.a. beschreven en toegelicht door James Wood in Hoe fictie werkt, onderscheiden en toepassen;\n",
      "aan de hand van aangereikte literaire teksten korte creatieve teksten schrijven;\n",
      "zaken als het vertelperspectief en de vrije indirecte rede zelf op creatieve wijze invoegen en uitwerken in een afgerond eigen verhaal;\n",
      "op respectvolle wijze feedback geven op het creatieve werk van medestudenten;\n",
      "eigen teksten herschrijven aan de hand van de ontvangen feedback.\n",
      "Content snippet: In het college Creatief schrijven verdiep je je in literaire technieken en leer je hoe je een verhaal schrijft. Als je zelf schrijft, begrijp je namelijk beter hoe het literaire mechaniek werkt (structuur, stijl, plot, genre, ruimte) en hoe je daarmee uitdrukking kunt geven aan de persoonlijke inzichten die je wilt overdragen in een verhaal. In een reeks colleges verdiep je je in de verschillende \n"
     ]
    }
   ],
   "source": [
    "# here we list all programme names, we still use this later for printing and merging\n",
    "programmes = sorted(df_courses_tasks[\"programme_title\"].unique())\n",
    "print(\"Number of programmes:\", len(programmes))\n",
    "print(\"First few programmes:\", programmes[:5])\n",
    "\n",
    "def build_course_context(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    With this function we build a short text snippet that describes one course.\n",
    "    We anchor the challenge at course level instead of programme level.\n",
    "\n",
    "    Input:\n",
    "        row: one row of df_courses_tasks\n",
    "\n",
    "    Output:\n",
    "        context: string that describes the programme and this specific course\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "\n",
    "    prog_name = row.get(\"programme_title\", \"\")\n",
    "    course_name = row.get(\"course_name\", \"\")\n",
    "    course_obj = row.get(\"course_objective\", \"\")\n",
    "    course_cont = row.get(\"course_content\", \"\")\n",
    "\n",
    "    if isinstance(prog_name, str) and prog_name.strip():\n",
    "        lines.append(f\"Programme: {prog_name.strip()}\")\n",
    "\n",
    "    if isinstance(course_name, str) and course_name.strip():\n",
    "        lines.append(f\"Course: {course_name.strip()}\")\n",
    "\n",
    "    if isinstance(course_obj, str) and course_obj.strip():\n",
    "        lines.append(f\"Objectives: {course_obj.strip()}\")\n",
    "\n",
    "    if isinstance(course_cont, str) and course_cont.strip():\n",
    "        # here we keep a short snippet to control prompt length\n",
    "        snippet = course_cont.strip()[:400]\n",
    "        lines.append(f\"Content snippet: {snippet}\")\n",
    "\n",
    "    context = \"\\n\".join(lines)\n",
    "    return context\n",
    "\n",
    "# here we test the course context builder on one random row\n",
    "sample_row = df_courses_tasks.sample(1, random_state=42).iloc[0]\n",
    "print(\"Sample course context:\")\n",
    "print(build_course_context(sample_row))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699462a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_aptitude_prompt(programme_name: str,\n",
    "                          course_name: str,\n",
    "                          course_context: str,\n",
    "                          task_type: str) -> str:\n",
    "    \"\"\"\n",
    "    With this function we build the text that we send to the model\n",
    "    to create one aptitude microchallenge for a specific course.\n",
    "    task_type can be \"classify\", \"fillblank\", \"puzzle\", \"codeorder\", or \"graph\".\n",
    "    \"\"\"\n",
    "    base = f\"\"\"\n",
    "    You are creating an aptitude micro challenge for a high school student of 16-17 years old\n",
    "    who is curious about the bachelor programme {programme_name}\n",
    "    and especially about the course {course_name}.\n",
    "\n",
    "    You receive a short context that summarises this single course.\n",
    "    You must anchor the challenge in this course context.\n",
    "    Do not invent domains that are unrelated to this course.\n",
    "    Use course topics, methods, and quantities that make sense for this course to generate the stimulus.\n",
    "    The question cannot be difficult and should not be too long. Must be related to the main topoics of \n",
    "    the course but use a bit of imagination. remenber that the student is 16-17 years old and the tasks are for \n",
    "    university orientation purposes. Make them very intresting and appealing to a curious high school student. The instructions must be clear.\n",
    "\n",
    "    The task must test ability or reasoning, not personal preference.\n",
    "    Use instructions such as \"Sort these\", \"Choose the correct\", \"Complete the text\",\n",
    "    \"Arrange the code lines\", or \"Select the correct part of a graph\".\n",
    "\n",
    "    General requirements:\n",
    "    - tiny_learn must be a list of exactly three short bullet points.\n",
    "    Each bullet explains one useful idea in simple language that fits this course.\n",
    "    - hint must be one short sentence that nudges the student without giving the answer away.\n",
    "    - signalType must always be \"aptitude\".\n",
    "    - The text of the task must clearly feel related to the course {course_name}.\n",
    "\"\"\"\n",
    "\n",
    "    if task_type == \"classify\":\n",
    "        specific = \"\"\"\n",
    "Task type: classify.\n",
    "\n",
    "You must return a JSON object with these fields:\n",
    "question_code: string, for example \"L_AABAOHW115_classify_1\"\n",
    "type: \"classify\"\n",
    "signalType: \"aptitude\"\n",
    "question: short instruction, for example \"Sort these concepts into qualitative or quantitative\"\n",
    "tiny_learn: list of exactly three strings\n",
    "categories: list of category labels, for example [\"Qualitative\", \"Quantitative\"]\n",
    "items: list of objects with fields:\n",
    "    id: short id such as \"a\" or \"b\"\n",
    "    text: short description of the item\n",
    "    correctCategory: one of the category labels\n",
    "hint: short sentence\n",
    "\n",
    "The categories and items must make sense for the course described in the context.\n",
    "\"\"\"\n",
    "\n",
    "    elif task_type == \"fillblank\":\n",
    "        specific = \"\"\"\n",
    "Task type: fillblank.\n",
    "\n",
    "You must return a JSON object with these fields:\n",
    "question_code: string, for example \"L_AABAOHW115_fillblank_1\"\n",
    "type: \"fillblank\"\n",
    "signalType: \"aptitude\"\n",
    "question: short instruction, for example \"Complete the text\"\n",
    "tiny_learn: list of exactly three strings\n",
    "textWithBlanks: short text that contains markers {{0}}, {{1}}, etc\n",
    "blanks: list of objects with fields:\n",
    "    id: integer index such as 0 or 1\n",
    "    correctWordId: id of the correct word from the words list\n",
    "words: list of objects with fields:\n",
    "    id: string, for example \"sumerian\"\n",
    "    text: the word as it should appear in the text\n",
    "hint: short sentence\n",
    "\n",
    "The text must describe something that fits the course context.\n",
    "\"\"\"\n",
    "\n",
    "    elif task_type == \"puzzle\":\n",
    "        specific = \"\"\"\n",
    "Task type: puzzle.\n",
    "\n",
    "You must return a JSON object with these fields and structure:\n",
    "question_code: string, for example \"L_AABAOHW115_puzzlebalance_1\"\n",
    "type: \"puzzle\"\n",
    "signalType: \"aptitude\"\n",
    "question: short instruction, for example \"If 2 triangles balance 3 circles, how many circles balance 4 triangles?\"\n",
    "tiny_learn: list of exactly three strings\n",
    "\n",
    "puzzle: object that describes the puzzle, for example:\n",
    "    {\n",
    "      \"variant\": \"balance\",\n",
    "      \"left\": [\n",
    "        { \"shape\": \"▲\", \"count\": 2 }\n",
    "      ],\n",
    "      \"right\": [\n",
    "        { \"shape\": \"●\", \"count\": 3 }\n",
    "      ],\n",
    "      \"unknownSide\": \"right\",\n",
    "      \"unknownShape\": \"●\"\n",
    "    }\n",
    "or:\n",
    "    {\n",
    "      \"variant\": \"pattern\",\n",
    "      \"sequence\": [\"1\",\"1\",\"2\",\"3\",\"5\",\"8\",\"?\"]\n",
    "    }\n",
    "\n",
    "options: list of objects with fields:\n",
    "    id: short letter id, \"a\", \"b\", \"c\", \"d\"\n",
    "    value: the option value, for example a number or a short string\n",
    "correctAnswer: id of the correct option, for example \"c\"\n",
    "hint: short sentence\n",
    "\n",
    "The puzzle must be solvable using proportional reasoning, pattern recognition,\n",
    "or basic logic at high school level, and must be clearly related to the math\n",
    "topics of the course context.\n",
    "\"\"\"\n",
    "\n",
    "    elif task_type == \"codeorder\":\n",
    "        specific = \"\"\"\n",
    "Task type: codeorder.\n",
    "\n",
    "You must return a JSON object with these fields:\n",
    "question_code: string, for example \"L_AABAOHW115_codeorder_5\"\n",
    "type: \"codeorder\"\n",
    "signalType: \"aptitude\"\n",
    "question: short instruction, for example \"Arrange the code lines to compute the correct average grade\"\n",
    "tiny_learn: list of exactly three strings\n",
    "language: must be \"python\"\n",
    "description: short description of what the code should do in the context of this course\n",
    "lines: list of objects with fields:\n",
    "    id: short id such as \"1\", \"2\", \"3\"\n",
    "    code: one line of python code as a string\n",
    "    correctPosition: integer that gives the correct position in the final order\n",
    "expectedOutput: short string that describes what the code prints or returns when correctly ordered\n",
    "hint: short sentence\n",
    "\n",
    "The code must be short and readable for a motivated high school student.\n",
    "It must connect to a context that makes sense for this course.\n",
    "The language must be python. Only python even if in the description another language is mentioned. ANd must be very simple.\n",
    "\"\"\"\n",
    "\n",
    "    elif task_type == \"graph\":\n",
    "        specific = \"\"\"\n",
    "Task type: graph.\n",
    "\n",
    "You must return a JSON object with these fields and structure:\n",
    "question_code: string, for example \"math-graph-001\"\n",
    "type: \"graph\"\n",
    "signalType: \"aptitude\"\n",
    "question: short instruction, for example\n",
    "    \"Looking at this graph of weekly study hours, which week showed the biggest increase?\"\n",
    "tiny_learn: list of exactly three strings\n",
    "\n",
    "graphData: object that describes a simple graph, for example:\n",
    "    {\n",
    "      \"type\": \"line\",\n",
    "      \"title\": \"Weekly Study Hours\",\n",
    "      \"labels\": [\"Week 1\", \"Week 2\", \"Week 3\", \"Week 4\", \"Week 5\"],\n",
    "      \"values\": [5, 7, 8, 14, 15],\n",
    "      \"yAxisLabel\": \"Hours\"\n",
    "    }\n",
    "or:\n",
    "    {\n",
    "      \"type\": \"bar\",\n",
    "      \"title\": \"Student Success Rates in Academic Skills\",\n",
    "      \"labels\": [\"Research Skills\", \"Argumentation\", \"Abstraction\"],\n",
    "      \"values\": [75, 85, 70]\n",
    "    }\n",
    "\n",
    "clickableRegions: list of objects with fields:\n",
    "    id: short id such as \"w1\", \"w2\", \"r1\"\n",
    "    label: label for the region or interval\n",
    "    dataIndex: optional integer index that points to a position in the values list,\n",
    "               used for line graphs when an interval spans two points\n",
    "\n",
    "correctRegion: id of the correct region from clickableRegions\n",
    "hint: short sentence\n",
    "\n",
    "The graph must be simple and use quantities that match the course context,\n",
    "for example exam scores, counts of artifacts, sample sizes, or weekly study hours.\n",
    "\"\"\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported task_type: {task_type}\")\n",
    "\n",
    "    context_block = f\"\"\"\n",
    "Course context:\n",
    "{course_context}\n",
    "\n",
    "Output format:\n",
    "Return a single valid JSON object and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "    return base + specific + context_block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641246c9",
   "metadata": {},
   "source": [
    "## 5. Generate one task per type per course, with question_code based on course code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "174ae3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aptitude_task_for_course(programme_name: str,\n",
    "                                      course_name: str,\n",
    "                                      course_context: str,\n",
    "                                      task_type: str) -> dict:\n",
    "    \"\"\"\n",
    "    With this function we call the model one time and return one aptitude task\n",
    "    parsed as a Python dict for a specific course.\n",
    "    \"\"\"\n",
    "    prompt = build_aptitude_prompt(\n",
    "        programme_name=programme_name,\n",
    "        course_name=course_name,\n",
    "        course_context=course_context,\n",
    "        task_type=task_type,\n",
    "    )\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=model_gpt,\n",
    "        input=prompt,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    raw = response.output[0].content[0].text.strip()\n",
    "\n",
    "    start = raw.find(\"{\")\n",
    "    end = raw.rfind(\"}\") + 1\n",
    "\n",
    "    if start == -1 or end <= start:\n",
    "        raise ValueError(\"We did not find a JSON object in the model output.\")\n",
    "\n",
    "    json_str = raw[start:end]\n",
    "    task = json.loads(json_str)\n",
    "\n",
    "    # we enforce general fields from our side\n",
    "    task[\"signalType\"] = \"aptitude\"\n",
    "    task[\"type\"] = task_type\n",
    "    task[\"programme_title\"] = programme_name\n",
    "    task[\"course_name\"] = course_name\n",
    "\n",
    "    # we normalise tiny_learn to exactly three bullets\n",
    "    tiny = task.get(\"tiny_learn\", [])\n",
    "    if not isinstance(tiny, list):\n",
    "        tiny = [str(tiny)]\n",
    "    if len(tiny) > 3:\n",
    "        tiny = tiny[:3]\n",
    "    while len(tiny) < 3:\n",
    "        tiny.append(\"Extra note about the concept.\")\n",
    "    task[\"tiny_learn\"] = tiny\n",
    "\n",
    "    # we strongly enforce language for codeorder\n",
    "    if task_type == \"codeorder\":\n",
    "        task[\"language\"] = \"python\"\n",
    "\n",
    "    return task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d7905a",
   "metadata": {},
   "source": [
    "Now we add a helper to build question_code in the format you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b13eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we map each task type to a stable index, so codes are consistent\n",
    "QUESTION_IDX_BY_TYPE = {\n",
    "    \"classify\": 1,\n",
    "    \"fillblank\": 2,\n",
    "    \"puzzle\": 3,\n",
    "    \"graph\": 4,\n",
    "    \"codeorder\": 5,\n",
    "}\n",
    "\n",
    "def build_question_code(row: pd.Series, task_type: str) -> str:\n",
    "    \"\"\"\n",
    "    With this function we build a question_code like L_AABAOHW115_fillblank_1\n",
    "    using the course code and the task type.\n",
    "\n",
    "    We expect a column called 'code' with values such as 'L_AABAOHW115'.\n",
    "    If that is missing, we fall back to a simple slug from the course name.\n",
    "    \"\"\"\n",
    "    course_code = row.get(\"code\", \"\")\n",
    "    if not isinstance(course_code, str) or not course_code.strip():\n",
    "        # here we take a simple fallback based on course name\n",
    "        name = str(row.get(\"course_name\", \"course\")).strip()\n",
    "        # we remove spaces and punctuation for a simple slug\n",
    "        slug = re.sub(r\"[^A-Za-z0-9]\", \"\", name)\n",
    "        course_code = slug or \"COURSE\"\n",
    "\n",
    "    idx = QUESTION_IDX_BY_TYPE.get(task_type, 0)\n",
    "    return f\"{course_code}_{task_type}_{idx}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cbc059",
   "metadata": {},
   "source": [
    "## 6. Testing before the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9806b73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After keeping two courses per programme for test:\n",
      "    programme_title            course_name      code\n",
      "0  Computer Science   Computer Programming  XB_40011\n",
      "1  Computer Science  Logic and Sets for CS   XB_0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating aptitude tasks for Computer Science: 100%|██████████| 2/2 [00:45<00:00, 22.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for test programme: Computer Science\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_programme = \"Computer Science\"  # change this to the programme we want\n",
    "\n",
    "# Here we filter the dataframe to keep only rows for this programme\n",
    "df_courses_test = df_courses_tasks[\n",
    "    df_courses_tasks[\"programme_title\"] == test_programme\n",
    "].copy()\n",
    "\n",
    "# Here we optionally keep only two core courses for this test\n",
    "df_courses_test = (\n",
    "    df_courses_test\n",
    "    .groupby(\"programme_title\", as_index=False)\n",
    "    .head(2)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"After keeping two courses per programme for test:\")\n",
    "print(df_courses_test[[\"programme_title\", \"course_name\", \"code\"]])\n",
    "\n",
    "# Here we define which base task types we use for every course\n",
    "BASE_TASK_TYPES = [\"classify\", \"fillblank\", \"graph\"]\n",
    "\n",
    "# Here we keep a small bank only for the test programme\n",
    "aptitude_bank_test: dict[str, dict] = {}\n",
    "\n",
    "for _, row in tqdm(\n",
    "    df_courses_test.iterrows(),\n",
    "    total=len(df_courses_test),\n",
    "    desc=f\"Generating aptitude tasks for {test_programme}\"\n",
    "):\n",
    "    prog = row[\"programme_title\"]\n",
    "    course_name = row[\"course_name\"]\n",
    "    ctx = build_course_context(row)\n",
    "\n",
    "    # Here we decide the task types for this course\n",
    "    task_types_for_course = list(BASE_TASK_TYPES)\n",
    "\n",
    "    # Puzzle only for math related courses\n",
    "    if bool(row.get(\"math_puzzle\", False)):\n",
    "        task_types_for_course.append(\"puzzle\")\n",
    "\n",
    "    # Codeorder only for python coding courses\n",
    "    if course_uses_python(row):\n",
    "        task_types_for_course.append(\"codeorder\")\n",
    "\n",
    "    tasks_for_this_course = []\n",
    "\n",
    "    for task_type in task_types_for_course:\n",
    "        try:\n",
    "            task = generate_aptitude_task_for_course(\n",
    "                programme_name=prog,\n",
    "                course_name=course_name,\n",
    "                course_context=ctx,\n",
    "                task_type=task_type,\n",
    "            )\n",
    "\n",
    "            # Here we build a stable question code for this course and type\n",
    "            task[\"question_code\"] = build_question_code(row, task_type)\n",
    "\n",
    "            tasks_for_this_course.append(task)\n",
    "        except Exception as e:\n",
    "            print(f\"Problem for course {course_name} task {task_type}: {e}\")\n",
    "\n",
    "    if not tasks_for_this_course:\n",
    "        continue\n",
    "\n",
    "    if prog not in aptitude_bank_test:\n",
    "        aptitude_bank_test[prog] = {\"aptitude\": []}\n",
    "    aptitude_bank_test[prog][\"aptitude\"].extend(tasks_for_this_course)\n",
    "\n",
    "print(\"Done for test programme:\", test_programme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce342b95",
   "metadata": {},
   "source": [
    "Run th loop that genrates the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "892830c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating aptitude microchallenges per course:  82%|████████▏ | 23/28 [07:56<01:40, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem for course Single Variable Calculus in programme Mathematics task type graph: Invalid \\escape: line 5 column 53 (char 138)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating aptitude microchallenges per course: 100%|██████████| 28/28 [09:23<00:00, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example programme: Ancient Studies\n",
      "Number of aptitude tasks for this programme: 6\n",
      "[\n",
      "  {\n",
      "    \"question_code\": \"L_AABAOHW115_classify_1\",\n",
      "    \"type\": \"classify\",\n",
      "    \"signalType\": \"aptitude\",\n",
      "    \"question\": \"Sort these ancient objects according to whether they primarily belong to the sacred, domestic, or funerary context.\",\n",
      "    \"tiny_learn\": [\n",
      "      \"Ancient objects can be grouped by the role they played in daily life or rituals.\",\n",
      "      \"Understanding the context of an object helps us learn about the people who used it.\",\n",
      "      \"Objects from sacred, domestic, or funerary contexts often tell different historical stories.\"\n",
      "    ],\n",
      "    \"categories\": [\n",
      "      \"Sacred\",\n",
      "      \"Domestic\",\n",
      "      \"Funerary\"\n",
      "    ],\n",
      "    \"items\": [\n",
      "      {\n",
      "        \"id\": \"a\",\n",
      "        \"text\": \"Bronze statue of a deity\",\n",
      "        \"correctCategory\": \"Sacred\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"b\",\n",
      "        \"text\": \"Clay cooking pot\",\n",
      "        \"correctCategory\": \"Domestic\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"c\",\n",
      "        \"text\": \"Funerary urn with ashes\",\n",
      "        \"correctCategory\": \"Funerary\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"d\",\n",
      "        \"text\": \"Stone relief from a temple wall\",\n",
      "        \"correctCategory\": \"Sacred\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"e\",\n",
      "        \"text\": \"Wooden chair used in a household\",\n",
      "        \"correctCategory\": \"Domestic\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"f\",\n",
      "        \"text\": \"Gold burial mask\",\n",
      "        \"correctCategory\": \"Funerary\"\n",
      "      }\n",
      "    ],\n",
      "    \"hint\": \"Think about where and why these objects were used in ancient times.\",\n",
      "    \"programme_title\": \"Ancient Studies\",\n",
      "    \"course_name\": \"Objects in Context. An Interdisciplinary Perspective on the Ancient World\"\n",
      "  },\n",
      "  {\n",
      "    \"question_code\": \"L_AABAOHW115_fillblank_2\",\n",
      "    \"type\": \"fillblank\",\n",
      "    \"signalType\": \"aptitude\",\n",
      "    \"question\": \"Complete the text\",\n",
      "    \"tiny_learn\": [\n",
      "      \"Material objects like statues and coins help us learn about ancient people's lives.\",\n",
      "      \"Objects must be studied in their historical context to understand their meaning.\",\n",
      "      \"Comparing objects with written texts can reveal different perspectives on the past.\"\n",
      "    ],\n",
      "    \"textWithBlanks\": \"In Ancient Studies, an object such as a {{0}} can tell us about trade and economy, while a {{1}} found in a tomb might reveal beliefs about the {{2}}.\",\n",
      "    \"blanks\": [\n",
      "      {\n",
      "        \"id\": 0,\n",
      "        \"correctWordId\": \"coin\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": 1,\n",
      "        \"correctWordId\": \"statue\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": 2,\n",
      "        \"correctWordId\": \"afterlife\"\n",
      "      }\n",
      "    ],\n",
      "    \"words\": [\n",
      "      {\n",
      "        \"id\": \"coin\",\n",
      "        \"text\": \"coin\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"statue\",\n",
      "        \"text\": \"statue\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"afterlife\",\n",
      "        \"text\": \"afterlife\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"utensil\",\n",
      "        \"text\": \"utensil\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"relief\",\n",
      "        \"text\": \"relief\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"market\",\n",
      "        \"text\": \"market\"\n",
      "      }\n",
      "    ],\n",
      "    \"hint\": \"Think about objects linked to economy, funerary customs, and beliefs.\",\n",
      "    \"programme_title\": \"Ancient Studies\",\n",
      "    \"course_name\": \"Objects in Context. An Interdisciplinary Perspective on the Ancient World\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# base task types that any course can receive\n",
    "BASE_TASK_TYPES = [\"classify\", \"fillblank\", \"graph\"]\n",
    "\n",
    "aptitude_bank: dict[str, dict] = {}\n",
    "\n",
    "for _, row in tqdm(\n",
    "    df_courses_tasks.iterrows(),\n",
    "    total=len(df_courses_tasks),\n",
    "    desc=\"Generating aptitude microchallenges per course\"\n",
    "):\n",
    "    prog = row[\"programme_title\"]\n",
    "    course_name = row[\"course_name\"]\n",
    "    ctx = build_course_context(row)\n",
    "\n",
    "    # here we decide which task types we want for this course\n",
    "    task_types_for_course = list(BASE_TASK_TYPES)\n",
    "\n",
    "    # puzzle only for math related courses\n",
    "    if bool(row.get(\"math_puzzle\", False)):\n",
    "        task_types_for_course.append(\"puzzle\")\n",
    "\n",
    "    # codeorder only for python coding courses\n",
    "    if course_uses_python(row):\n",
    "        task_types_for_course.append(\"codeorder\")\n",
    "\n",
    "    tasks_for_this_course = []\n",
    "\n",
    "    for task_type in task_types_for_course:\n",
    "        try:\n",
    "            task = generate_aptitude_task_for_course(\n",
    "                programme_name=prog,\n",
    "                course_name=course_name,\n",
    "                course_context=ctx,\n",
    "                task_type=task_type,\n",
    "            )\n",
    "            # here we override question_code so it follows the L_AABAOHW115_fillblank_1 pattern\n",
    "            task[\"question_code\"] = build_question_code(row, task_type)\n",
    "            tasks_for_this_course.append(task)\n",
    "        except Exception as e:\n",
    "            print(f\"Problem for course {course_name} in programme {prog} task type {task_type}: {e}\")\n",
    "\n",
    "    if not tasks_for_this_course:\n",
    "        continue\n",
    "\n",
    "    # here we store the aptitude tasks grouped by programme\n",
    "    if prog not in aptitude_bank:\n",
    "        aptitude_bank[prog] = {\"aptitude\": []}\n",
    "    aptitude_bank[prog][\"aptitude\"].extend(tasks_for_this_course)\n",
    "\n",
    "# quick sample to inspect\n",
    "sample_prog = programmes[0]\n",
    "print(\"Example programme:\", sample_prog)\n",
    "print(\"Number of aptitude tasks for this programme:\",\n",
    "      len(aptitude_bank.get(sample_prog, {}).get(\"aptitude\", [])))\n",
    "if aptitude_bank.get(sample_prog, {}).get(\"aptitude\"):\n",
    "    print(json.dumps(aptitude_bank[sample_prog][\"aptitude\"][:2], indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b4905",
   "metadata": {},
   "source": [
    "Saving the challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbf5eee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full microtasks bank to: ..\\data_bank_microtasks\\microchallenges_bank_aptitude.json\n",
      "Number of programmes in the full bank: 14\n",
      "Sample programme: Ancient Studies\n",
      "Keys for this programme: dict_keys(['aptitude'])\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"../data_bank_microtasks\")\n",
    "full_bank_path = data_dir / \"microchallenges_bank_aptitude.json\"\n",
    "\n",
    "with open(full_bank_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(aptitude_bank, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved full microtasks bank to:\", full_bank_path)\n",
    "print(\"Number of programmes in the full bank:\", len(aptitude_bank))\n",
    "\n",
    "# here we quickly check that one programme has both personality and aptitude if personality existed\n",
    "sample_prog = programmes[0]\n",
    "print(\"Sample programme:\", sample_prog)\n",
    "print(\"Keys for this programme:\", aptitude_bank.get(sample_prog, {}).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35393742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing microtasks_RIASEC.json\n",
      "Saved full microtasks bank to: ..\\data_bank_microtasks\\microtasks_bank_full.json\n",
      "Number of programmes in the full bank: 14\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"../data_bank_microtasks\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "base_bank_path = data_dir / \"microtasks_RIASEC.json\"\n",
    "\n",
    "if base_bank_path.exists():\n",
    "    with open(base_bank_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        microtasks_bank = json.load(f)\n",
    "    print(\"Loaded existing microtasks_RIASEC.json\")\n",
    "else:\n",
    "    microtasks_bank = {}\n",
    "    print(\"No existing microtasks_RIASEC.json found, we start from an empty bank\")\n",
    "\n",
    "for prog, block in aptitude_bank.items():\n",
    "    if prog not in microtasks_bank:\n",
    "        microtasks_bank[prog] = {}\n",
    "    microtasks_bank[prog][\"aptitude\"] = block[\"aptitude\"]\n",
    "\n",
    "full_bank_path = data_dir / \"microtasks_bank_full.json\"\n",
    "with open(full_bank_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(microtasks_bank, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved full microtasks bank to:\", full_bank_path)\n",
    "print(\"Number of programmes in the full bank:\", len(microtasks_bank))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
