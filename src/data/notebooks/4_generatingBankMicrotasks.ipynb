{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4297891",
   "metadata": {},
   "source": [
    "# 4 Generating the Bank for the MicroTasks\n",
    "\n",
    "To generate the bank for the microtasks I will use an API for an LLM.\n",
    "The elemens that I will need are:\n",
    "\n",
    "1) Question\n",
    "2) Braoad options (all 6 letters)\n",
    "3) Shorter options (only 3)\n",
    "4) The \"Reading material\"\n",
    "\n",
    "\n",
    "Basically I will create the perfect prompt that will use the columns of the df_courses to generate the microstasks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a37def8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import openai\n",
    "print(openai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6274530",
   "metadata": {},
   "source": [
    "## 1 Load the data and filter for max 2 courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "209c821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the courses tasks dataframe is: (21, 21)\n",
      "After keeping only first two courses from each programme the shape is: (14, 21)\n"
     ]
    }
   ],
   "source": [
    "# load the csv file about the courses forwhih we have to gen the tasks\n",
    "silver = Path(\"../data_programmes_courses/silver\")\n",
    "\n",
    "df_courses_tasks = pd.read_csv(silver / \"df_courses_tasks_silver.csv\", encoding=\"utf-8-sig\")\n",
    "print(\"The shape of the courses tasks dataframe is:\", df_courses_tasks.shape)\n",
    "\n",
    "# keep only first two courses from each programme\n",
    "df_courses_tasks = df_courses_tasks.groupby(\"programme_title\").head(2).reset_index(drop=True)\n",
    "print(\"After keeping only first two courses from each programme the shape is:\", df_courses_tasks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1387546c",
   "metadata": {},
   "source": [
    "## 2. Set up the client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c7c36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Create the OpenAI client\n",
    "def get_openai_client():\n",
    "    \"\"\"\n",
    "    Read the API key from a local file and return a client.\n",
    "    The secrets folder is gitignored so the key never reaches the repo.\n",
    "    \"\"\"\n",
    "    key_path = Path(\"../data_bank_microtasks\") / \"api_key.txt\"\n",
    "\n",
    "    # Read the key and strip spaces and newlines\n",
    "    api_key = key_path.read_text(encoding=\"utf8\").strip()\n",
    "\n",
    "    # Create the client using this key\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    return client\n",
    "\n",
    "# Create the client once\n",
    "client = get_openai_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3092889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tts-1\n",
      "dall-e-2\n",
      "tts-1-1106\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-audio\n",
      "gpt-4o-mini-tts\n",
      "gpt-4-turbo\n",
      "gpt-realtime\n",
      "gpt-realtime-2025-08-28\n",
      "gpt-4.1-mini\n",
      "gpt-4.1-mini-2025-04-14\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-4-0125-preview\n",
      "davinci-002\n",
      "gpt-4-turbo-preview\n",
      "gpt-4-0613\n",
      "gpt-4\n",
      "gpt-4.1\n",
      "gpt-5.1-chat-latest\n",
      "gpt-4.1-2025-04-14\n",
      "dall-e-3\n",
      "gpt-4.1-nano\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "whisper-1\n",
      "o1-2024-12-17\n",
      "gpt-4.1-nano-2025-04-14\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-audio-2025-08-28\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-4o-2024-11-20\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-mini-search-preview\n",
      "gpt-4o-mini-search-preview-2025-03-11\n",
      "gpt-4o-search-preview\n",
      "omni-moderation-latest\n",
      "o1-pro\n",
      "o1-pro-2025-03-19\n",
      "gpt-5.1-codex-mini\n",
      "gpt-4o-search-preview-2025-03-11\n",
      "text-embedding-ada-002\n",
      "gpt-4o-2024-08-06\n",
      "o1\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-audio-preview\n",
      "gpt-image-1-mini\n",
      "gpt-5-mini\n",
      "gpt-image-1\n",
      "gpt-5-mini-2025-08-07\n",
      "omni-moderation-2024-09-26\n",
      "gpt-5\n",
      "gpt-5-nano-2025-08-07\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "gpt-5-nano\n",
      "gpt-5.1-2025-11-13\n",
      "tts-1-hd-1106\n",
      "tts-1-hd\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-audio-mini\n",
      "gpt-audio-mini-2025-10-06\n",
      "gpt-5.1\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "o3-mini-2025-01-31\n",
      "o3-mini\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "gpt-4-1106-preview\n",
      "babbage-002\n",
      "gpt-5-chat-latest\n",
      "gpt-3.5-turbo\n",
      "gpt-5-2025-08-07\n",
      "chatgpt-4o-latest\n",
      "text-embedding-3-small\n",
      "gpt-4o-transcribe\n",
      "sora-2\n",
      "sora-2-pro\n",
      "gpt-5-pro-2025-10-06\n",
      "gpt-4o\n",
      "gpt-4o-realtime-preview\n",
      "gpt-realtime-mini\n",
      "gpt-realtime-mini-2025-10-06\n",
      "o4-mini\n",
      "gpt-4o-realtime-preview-2025-06-03\n",
      "o4-mini-2025-04-16\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-audio-preview-2025-06-03\n",
      "gpt-5-pro\n",
      "text-embedding-3-large\n",
      "gpt-4o-mini-transcribe\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "o3\n",
      "gpt-5-codex\n",
      "o3-2025-04-16\n",
      "gpt-4o-transcribe-diarize\n",
      "gpt-4o-audio-preview-2024-10-01\n",
      "gpt-4o-realtime-preview-2024-10-01\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "for m in models.data:\n",
    "    print(m.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420eae5",
   "metadata": {},
   "source": [
    "## 3. Define the Prompt\n",
    "The system prompt carries all project logic once. We reuse it for all courses.\n",
    "\n",
    "\n",
    "CHANGE: based on the programme vectors such as A: best 2, B medium two an C lowest 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c797527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You create a single multiple choice microtask that feels like a first step in a real course task.\n",
    "\n",
    "You will receive one JSON object with these fields:\n",
    "- course_code\n",
    "- course_name\n",
    "- course_objective\n",
    "- course_content\n",
    "- additional_information_teaching_methods\n",
    "- method_of_assessment\n",
    "- template_type   one of graph_choice, assumption_check, operational_definition, design_choice\n",
    "\n",
    "General rules:\n",
    "1. Pick one concrete concept or method from the text.\n",
    "2. Write a short stimulus that sounds like a real situation for a first year student in this course.\n",
    "3. Create one tiny learn bubble with three short bullet points:\n",
    "   a. definition\n",
    "   b. method reminder\n",
    "   c. common pitfall\n",
    "4. Create four options A, B, C, D. Only one is the best first step. Others are plausible but wrong first steps.\n",
    "5. Keep language simple and concrete. Do not mention RIASEC in the text.\n",
    "\n",
    "Template rules:\n",
    "- graph_choice: stimulus names two variables and a goal. Options are graph types, one correct.\n",
    "- assumption_check: stimulus names an analysis decision. Options are checks or tests to do first.\n",
    "- operational_definition: stimulus names a vague construct. Options are observable measurements.\n",
    "- design_choice: stimulus names a research or design goal. Options are study designs or data collection strategies.\n",
    "\n",
    "\n",
    "Output format:\n",
    "Return one JSON object with keys:\n",
    "- stimulus: string\n",
    "- tiny_learn: list of three short strings\n",
    "- options: list of four option objects with keys \"label\" and \"text\"\n",
    "- correct_option: label of the best option, one of \"A\",\"B\",\"C\",\"D\"\n",
    "\n",
    "Very important:\n",
    "Reply with a single JSON object only.\n",
    "Start your reply with { and end your reply with }.\n",
    "Do not wrap the JSON in code fences.\n",
    "Do not add any explanation, commentary, or text outside the JSON object.\n",
    "\n",
    "Do not add any explanation outside the JSON object.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6fa2f",
   "metadata": {},
   "source": [
    "## 4. Define the helpers functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb9a232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def truncate(text, max_chars=1200):\n",
    "    \"\"\"\n",
    "    Simple helper to shorten long course texts.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    s = str(text)\n",
    "    if len(s) <= max_chars:\n",
    "        return s\n",
    "    return s[:max_chars]\n",
    "\n",
    "\n",
    "def build_course_payload(row, template_type):\n",
    "    \"\"\"\n",
    "    Prepare the JSON object that will be sent to the model for one course.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"course_code\": str(row.get(\"code\", \"\")),\n",
    "        \"course_name\": str(row.get(\"course_name\", \"\")),\n",
    "        \"course_objective\": truncate(row.get(\"course_objective\", \"\"), 1200),\n",
    "        \"course_content\": truncate(row.get(\"course_content\", \"\"), 1200),\n",
    "        \"additional_information_teaching_methods\": truncate(\n",
    "            row.get(\"additional_information_teaching_methods\", \"\"), 800\n",
    "        ),\n",
    "        \"method_of_assessment\": truncate(row.get(\"method_of_assessment\", \"\"), 800),\n",
    "        \"template_type\": template_type,\n",
    "    }\n",
    "\n",
    "\n",
    "def safe_parse_json(raw_text):\n",
    "    \"\"\"\n",
    "    Try to parse the model output as JSON.\n",
    "    If that fails, try to extract the first {...} block.\n",
    "    If that also fails, raise a clear error.\n",
    "    \"\"\"\n",
    "    if raw_text is None:\n",
    "        raise ValueError(\"Model returned no text at all\")\n",
    "\n",
    "    text = raw_text.strip()\n",
    "\n",
    "    # If the model returned an empty string\n",
    "    if not text:\n",
    "        raise ValueError(\"Model returned an empty string, no JSON to parse\")\n",
    "\n",
    "    # First simple attempt\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # Second attempt, look for first and last curly brace\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start == -1 or end == -1 or end <= start:\n",
    "        print(\"Could not find any JSON object in the text. Here is a preview:\")\n",
    "        print(text[:400])\n",
    "        raise ValueError(\"No JSON object found in model output\")\n",
    "\n",
    "    candidate = text[start : end + 1]\n",
    "\n",
    "    try:\n",
    "        return json.loads(candidate)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to parse this JSON candidate:\")\n",
    "        print(candidate[:400])\n",
    "        raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afebd4b",
   "metadata": {},
   "source": [
    "## 5. API call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d93ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_microtask_for_row(row, template_type=\"graph_choice\", model_name=\"gpt-4.1-mini\"):\n",
    "    \"\"\"\n",
    "    Call the Responses API for a single course row and a single template type.\n",
    "\n",
    "    Returns a Python dict with the parsed microtask plus some metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    payload = build_course_payload(row, template_type)\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=model_name,\n",
    "        input=json.dumps(payload),\n",
    "        instructions=SYSTEM_PROMPT,\n",
    "        max_output_tokens=500,\n",
    "    )\n",
    "\n",
    "    raw_text = response.output_text\n",
    "\n",
    "    # Debug print for the first few characters so we know what came back\n",
    "    print(\"RAW TEXT PREVIEW:\")\n",
    "    print(repr((raw_text or \"\")[:300]))\n",
    "    print(\"END RAW TEXT PREVIEW\\n\")\n",
    "\n",
    "    # If the model returned nothing at all, fail early with context\n",
    "    if raw_text is None or not raw_text.strip():\n",
    "        print(\"Full response object for debugging:\")\n",
    "        print(response)\n",
    "        raise ValueError(\"Model returned no text, check model name and prompt\")\n",
    "\n",
    "    # Use the safe parser\n",
    "    task = safe_parse_json(raw_text)\n",
    "\n",
    "    task[\"course_code\"] = str(row.get(\"code\", \"\"))\n",
    "    task[\"course_name\"] = str(row.get(\"course_name\", \"\"))\n",
    "    task[\"template_type\"] = template_type\n",
    "\n",
    "    return task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e626e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW TEXT PREVIEW:\n",
      "'{\\n  \"stimulus\": \"You are studying the relationship between the age of ancient coins (years since minting) and the amount of wear they display, with the goal to visualize this relationship clearly.\",\\n  \"tiny_learn\": [\\n    \"Scatter plots show relationships between two continuous variables.\",\\n    \"Plot'\n",
      "END RAW TEXT PREVIEW\n",
      "\n",
      "{\n",
      "  \"stimulus\": \"You are studying the relationship between the age of ancient coins (years since minting) and the amount of wear they display, with the goal to visualize this relationship clearly.\",\n",
      "  \"tiny_learn\": [\n",
      "    \"Scatter plots show relationships between two continuous variables.\",\n",
      "    \"Plot age on the x-axis and wear on the y-axis to see trends.\",\n",
      "    \"Avoid bar charts as they do not show continuous data well.\"\n",
      "  ],\n",
      "  \"options\": [\n",
      "    {\n",
      "      \"label\": \"A\",\n",
      "      \"text\": \"Create a scatter plot with coin age on the x-axis and wear level on the y-axis.\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"B\",\n",
      "      \"text\": \"Make a bar chart showing average wear for different coin age groups.\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"C\",\n",
      "      \"text\": \"Use a pie chart to show proportions of coins by wear categories.\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"D\",\n",
      "      \"text\": \"Draw a line graph with wear level on the x-axis and coin age on the y-axis.\"\n",
      "    }\n",
      "  ],\n",
      "  \"correct_option\": \"A\",\n",
      "  \"course_code\": \"L_AABAOHW115\",\n",
      "  \"course_name\": \"Objects in Context. An Interdisciplinary Perspective on the Ancient World\",\n",
      "  \"template_type\": \"graph_choice\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "test_row = df_courses_tasks.iloc[0]\n",
    "test_task = generate_microtask_for_row(test_row, template_type=\"graph_choice\")\n",
    "print(json.dumps(test_task, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46795be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW TEXT START\n",
      "'{\\n  \"stimulus\": \"You want to explore how the age of ancient coins relates to the number of symbols engraved on them to understand changes over time.\",\\n  \"tiny_learn\": [\\n    \"Definition: A scatterplot displays data points to show relationships between two numeric variables.\",\\n    \"Method reminder: Scatterplots help visualize if one variable changes with another, like age vs. number of symbols.\",\\n    \"Common pitfall: Bar charts or pie charts are not suitable for showing relationships between numer'\n",
      "RAW TEXT END\n"
     ]
    }
   ],
   "source": [
    "test_row = df_courses_tasks.iloc[0]\n",
    "\n",
    "payload = build_course_payload(test_row, \"graph_choice\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",   # see note on model names below\n",
    "    input=json.dumps(payload),\n",
    "    instructions=SYSTEM_PROMPT,\n",
    "    max_output_tokens=500,\n",
    ")\n",
    "\n",
    "raw_text = response.output_text\n",
    "print(\"RAW TEXT START\")\n",
    "print(repr(raw_text[:500]))\n",
    "print(\"RAW TEXT END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7b0e2",
   "metadata": {},
   "source": [
    "## 6.Loop over courses, pick templates, save tasks\n",
    "\n",
    "Now build a simple loop that chooses a template for each course, calls the function, and collects results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b492d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm  # optional progress bar, pip install tqdm\n",
    "\n",
    "TEMPLATE_TYPES = [\n",
    "    \"graph_choice\",\n",
    "    \"assumption_check\",\n",
    "    \"operational_definition\",\n",
    "    \"design_choice\",\n",
    "]\n",
    "\n",
    "def pick_template_type(row):\n",
    "    \"\"\"\n",
    "    Simple template picker.\n",
    "\n",
    "    Right now it just samples at random.\n",
    "    Later you can use smarter rules based on the content.\n",
    "    \"\"\"\n",
    "    return np.random.choice(TEMPLATE_TYPES)\n",
    "\n",
    "\n",
    "microtasks = []\n",
    "\n",
    "# Limit for a first run to avoid burning a lot of tokens\n",
    "max_tasks = 10\n",
    "\n",
    "for i, (_, row) in enumerate(tqdm(df_courses_tasks.iterrows(), total=len(df_courses_tasks))):\n",
    "    if i >= max_tasks:\n",
    "        break\n",
    "\n",
    "    template_type = pick_template_type(row)\n",
    "\n",
    "    try:\n",
    "        task = generate_microtask_for_row(row, template_type=template_type)\n",
    "        microtasks.append(task)\n",
    "    except Exception as e:\n",
    "        # Simple error handling so one bad course does not kill the whole run\n",
    "        print(f\"Problem on row {i} with course {row.get('code')}: {e}\")\n",
    "\n",
    "\n",
    "# Turn into a dataframe or save as json lines\n",
    "tasks_df = pd.DataFrame(microtasks)\n",
    "print(tasks_df.head())\n",
    "\n",
    "tasks_df.to_json(\n",
    "    \"microtasks.jsonl\",\n",
    "    orient=\"records\",\n",
    "    lines=True,\n",
    "    force_ascii=False,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
