{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4297891",
   "metadata": {},
   "source": [
    "# 4 Generating the Bank for the MicroTasks\n",
    "\n",
    "To generate the bank for the microtasks I will use an API for an LLM.\n",
    "The output will be two questions for each core course of each programme.\n",
    "\n",
    "Basically I will create the perfect prompt that will use the columns of the df_courses to generate the microstasks. \n",
    "\n",
    "We use two prompts: broad + disambiguaition (Kenneth Style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a37def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "#!pip install --upgrade openai\n",
    "import os, re\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # optional progress bar, pip install tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6274530",
   "metadata": {},
   "source": [
    "## 1 Load the data and filter for max 2 courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209c821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the courses tasks dataframe is: (36, 21)\n",
      "After keeping only first two courses from each programme the shape is: (28, 21)\n"
     ]
    }
   ],
   "source": [
    "# load the csv file about the courses forwhih we have to gen the tasks\n",
    "silver = Path(\"../data_programmes_courses/silver\")\n",
    "\n",
    "df_courses_tasks = pd.read_csv(silver / \"df_courses_tasks_silver.csv\", encoding=\"utf-8-sig\")\n",
    "print(\"The shape of the courses tasks dataframe is:\", df_courses_tasks.shape)\n",
    "\n",
    "# keep only first two courses from each programme\n",
    "df_courses_tasks = df_courses_tasks.groupby(\"programme_title\").head(2).reset_index(drop=True)\n",
    "print(\"After keeping only first two courses from each programme the shape is:\", df_courses_tasks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1387546c",
   "metadata": {},
   "source": [
    "## 2. Set up OpenAI client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7c36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_path = Path(\"../data_bank_microtasks\") / \"api_key.txt\"\n",
    "\n",
    "# Read the key and strip spaces and newlines\n",
    "api_key = key_path.read_text(encoding=\"utf8\").strip()\n",
    "\n",
    "# Create the client using this key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "models = client.models.list()\n",
    "#for m in models.data:\n",
    "#    print(m.id)\n",
    "\n",
    "model_gpt = \"gpt-4.1-mini\"  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420eae5",
   "metadata": {},
   "source": [
    "## 3. Define the Prompts\n",
    "Here is the prompt that generates for each programme the questions based on the core courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0306e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_BROAD = \"\"\"\n",
    "You generate one broad RIASEC question for a playful study choice tool.\n",
    "\n",
    "The question should feel like a first step in a real course task.\n",
    "\n",
    "INPUT\n",
    "You receive one JSON object with:\n",
    "- programme_title\n",
    "- course_code\n",
    "- course_name\n",
    "- course_objective\n",
    "- course_content\n",
    "- teaching_methods\n",
    "- assessment\n",
    "\n",
    "TASK\n",
    "Create exactly one multiple choice question with six options.\n",
    "\n",
    "Rules\n",
    "1. Use the course information to imagine a realistic first year situation.\n",
    "2. Write a short question string that describes the situation and ends with a question.\n",
    "3. Create tiny_learn as a list of exactly three short sentences:\n",
    "   a. definition of the key concept\n",
    "   b. method reminder\n",
    "   c. common mistake\n",
    "4. Create six options labelled A to F.\n",
    "5. Each option describes a plausible first action the student could take.\n",
    "6. Each option must be tagged with one RIASEC code:\n",
    "   R, I, A, S, E, or C.\n",
    "7. Across the six options you must use each of the six RIASEC codes exactly once.\n",
    "8. Do not mention RIASEC, personality, or profiles in the visible text.\n",
    "\n",
    "OUTPUT\n",
    "Return one JSON object with this shape:\n",
    "\n",
    "{\n",
    "  \"question\": string,\n",
    "  \"tiny_learn\": [string, string, string],\n",
    "  \"options\": {\n",
    "    \"A\": {\"text\": string, \"riasec\": \"R\" | \"I\" | \"A\" | \"S\" | \"E\" | \"C\"},\n",
    "    \"B\": {...},\n",
    "    \"C\": {...},\n",
    "    \"D\": {...},\n",
    "    \"E\": {...},\n",
    "    \"F\": {...}\n",
    "  }\n",
    "}\n",
    "\n",
    "All strings must be single line strings. Do not insert raw newline characters in any value.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_DISAMB = \"\"\"\n",
    "You generate one RIASEC disambiguation question for a playful study choice tool.\n",
    "\n",
    "The question should feel like a first step in a real course task.\n",
    "\n",
    "INPUT\n",
    "You receive one JSON object with:\n",
    "- programme_title\n",
    "- course_code\n",
    "- course_name\n",
    "- course_objective\n",
    "- course_content\n",
    "- teaching_methods\n",
    "- assessment\n",
    "- triple_code   for example \"RIA\"\n",
    "\n",
    "triple_code contains three distinct letters from R, I, A, S, E, C.\n",
    "\n",
    "TASK\n",
    "Create exactly one multiple choice question with three options.\n",
    "\n",
    "Rules\n",
    "1. Use the course information to imagine a realistic first year situation.\n",
    "2. Write a short question string that describes the situation and ends with a question.\n",
    "3. Create tiny_learn as a list of exactly three short sentences:\n",
    "   a. definition of the key concept\n",
    "   b. method reminder\n",
    "   c. common mistake\n",
    "4. Create three options labelled A, B, C.\n",
    "5. The three options together must use exactly the three letters in triple_code, one per option.\n",
    "   For example triple_code \"RIA\" means one R, one I, one A.\n",
    "6. Each option describes a plausible first action the student could take.\n",
    "7. Each option must be tagged with a riasec letter that is one of the letters in triple_code.\n",
    "8. Do not mention RIASEC, personality, or profiles in the visible text.\n",
    "\n",
    "OUTPUT\n",
    "Return one JSON object with this shape:\n",
    "\n",
    "{\n",
    "  \"question\": string,\n",
    "  \"tiny_learn\": [string, string, string],\n",
    "  \"options\": {\n",
    "    \"A\": {\"text\": string, \"riasec\": one letter from triple_code},\n",
    "    \"B\": {...},\n",
    "    \"C\": {...}\n",
    "  }\n",
    "}\n",
    "\n",
    "All strings must be single line strings. Do not insert raw newline characters in any value.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6fa2f",
   "metadata": {},
   "source": [
    "## 4. Define the helpers functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9a232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def truncate(text, max_chars=1200):\n",
    "    \"\"\"Short helper to shorten very long fields.\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    s = str(text)\n",
    "    if len(s) <= max_chars:\n",
    "        return s\n",
    "    return s[:max_chars]\n",
    "\n",
    "def build_course_payload(row):\n",
    "    \"\"\"Context that we pass to the model for one course.\"\"\"\n",
    "    return {\n",
    "        \"programme_title\": str(row.get(\"programme_title\", \"\")),\n",
    "        \"course_code\": str(row.get(\"code\", \"\")),\n",
    "        \"course_name\": str(row.get(\"course_name\", \"\")),\n",
    "        \"course_objective\": truncate(row.get(\"course_objective\", \"\"), 800),\n",
    "        \"course_content\": truncate(row.get(\"course_content\", \"\"), 800),\n",
    "        \"teaching_methods\": truncate(row.get(\"additional_information_teaching_methods\", \"\"), 400),\n",
    "        \"assessment\": truncate(row.get(\"method_of_assessment\", \"\"), 400),\n",
    "    }\n",
    "\n",
    "def safe_parse_json(raw_text: str):\n",
    "    \"\"\"\n",
    "    Clean and parse model output as JSON.\n",
    "    Removes newlines and obvious trailing commas, then parses.\n",
    "    \"\"\"\n",
    "    if raw_text is None:\n",
    "        raise ValueError(\"Model returned no text\")\n",
    "\n",
    "    text = raw_text.strip()\n",
    "    if not text:\n",
    "        raise ValueError(\"Model returned empty text\")\n",
    "\n",
    "    # normalise whitespace\n",
    "    text = text.replace(\"\\r\\n\", \" \").replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # remove trailing commas before closing braces or brackets\n",
    "    text = re.sub(r\",\\s*([}\\]])\", r\"\\1\", text)\n",
    "\n",
    "    # try direct\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # try first and last brace\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start == -1 or end == -1 or end <= start:\n",
    "        print(\"Could not find JSON object, preview:\")\n",
    "        print(text[:400])\n",
    "        raise ValueError(\"No JSON object found\")\n",
    "\n",
    "    candidate = text[start : end + 1]\n",
    "    candidate = re.sub(r\",\\s*([}\\]])\", r\"\\1\", candidate)\n",
    "\n",
    "    try:\n",
    "        return json.loads(candidate)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Still could not parse, preview:\")\n",
    "        print(candidate[:400])\n",
    "        raise e\n",
    "\n",
    "\n",
    "def call_broad_question(row, model_name=model_gpt):\n",
    "    payload = build_course_payload(row)\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=model_name,\n",
    "        input=json.dumps(payload),\n",
    "        instructions=SYSTEM_PROMPT_BROAD,\n",
    "        max_output_tokens=500,\n",
    "    )\n",
    "\n",
    "    raw = response.output_text\n",
    "    print(\"BROAD PREVIEW:\", repr((raw or \"\")[:160]))\n",
    "    return safe_parse_json(raw)\n",
    "\n",
    "\n",
    "def call_disamb_question(row, triple_code, model_name=model_gpt):\n",
    "    payload = build_course_payload(row)\n",
    "    payload[\"triple_code\"] = triple_code\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=model_name,\n",
    "        input=json.dumps(payload),\n",
    "        instructions=SYSTEM_PROMPT_DISAMB,\n",
    "        max_output_tokens=400,\n",
    "    )\n",
    "\n",
    "    raw = response.output_text\n",
    "    print(f\"DISAMB {triple_code} PREVIEW:\", repr((raw or \"\")[:160]))\n",
    "    return safe_parse_json(raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afebd4b",
   "metadata": {},
   "source": [
    "## 5. Function that calls the API and provide the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d93ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "TRIPLES = [\"RIA\", \"RIS\", \"REC\", \"IEC\", \"ASE\", \"ASC\"]\n",
    "\n",
    "# final result:\n",
    "# {\n",
    "#   \"Programme\": {\n",
    "#       \"broad\": [ {question_code, question, tiny_learn, options}, ... ],\n",
    "#       \"R\": [ {question_code, question, tiny_learn, options}, ... ],\n",
    "#       \"I\": [...], \"A\": [...], \"S\": [...], \"E\": [...], \"C\": [...]\n",
    "#   }\n",
    "# }\n",
    "ml_structure = defaultdict(lambda: {\n",
    "    \"broad\": [],\n",
    "    \"R\": [],\n",
    "    \"I\": [],\n",
    "    \"A\": [],\n",
    "    \"S\": [],\n",
    "    \"E\": [],\n",
    "    \"C\": [],\n",
    "})\n",
    "\n",
    "# track how many questions we have emitted per course\n",
    "from collections import Counter\n",
    "question_counter = Counter()\n",
    "\n",
    "max_courses = 100   # start small, then increase\n",
    "\n",
    "for i, (_, row) in enumerate(tqdm(df_courses_tasks.iterrows(), total=len(df_courses_tasks))):\n",
    "    if i >= max_courses:\n",
    "        break\n",
    "\n",
    "    programme = str(row.get(\"programme_title\", \"UNKNOWN PROGRAMME\"))\n",
    "    course_code = str(row.get(\"code\", \"\"))\n",
    "\n",
    "    # 1) broad question for this course\n",
    "    try:\n",
    "        broad_obj = call_broad_question(row)\n",
    "    except Exception as e:\n",
    "        print(f\"Problem making broad question for course {course_code}: {e}\")\n",
    "        continue\n",
    "\n",
    "    question_counter[course_code] += 1\n",
    "    broad_qcode = f\"{course_code}_{question_counter[course_code]}\"\n",
    "\n",
    "    broad_entry = {\n",
    "        \"question_code\": broad_qcode,\n",
    "        \"question\": broad_obj[\"question\"],\n",
    "        \"tiny_learn\": broad_obj[\"tiny_learn\"],\n",
    "        \"options\": broad_obj[\"options\"],\n",
    "    }\n",
    "\n",
    "    ml_structure[programme][\"broad\"].append(broad_entry)\n",
    "\n",
    "    # 2) six disambiguation questions for this course\n",
    "    for triple in TRIPLES:\n",
    "        try:\n",
    "            disamb_obj = call_disamb_question(row, triple)\n",
    "        except Exception as e:\n",
    "            print(f\"Problem making disamb {triple} for course {course_code}: {e}\")\n",
    "            continue\n",
    "\n",
    "        question_counter[course_code] += 1\n",
    "        disamb_qcode = f\"{course_code}_{question_counter[course_code]}\"\n",
    "\n",
    "        disamb_entry = {\n",
    "            \"question_code\": disamb_qcode,\n",
    "            \"question\": disamb_obj[\"question\"],\n",
    "            \"tiny_learn\": disamb_obj[\"tiny_learn\"],\n",
    "            \"options\": disamb_obj[\"options\"],\n",
    "        }\n",
    "\n",
    "        # attach under each RIASEC letter in the triple\n",
    "        for letter in set(triple):\n",
    "            if letter in \"RIASEC\":\n",
    "                ml_structure[programme][letter].append(disamb_entry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b033aa7",
   "metadata": {},
   "source": [
    "## 6. Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c77a917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ML structure to: ..\\data_bank_microtasks\\microtasks_prototype.json\n"
     ]
    }
   ],
   "source": [
    "ml_structure = dict(ml_structure)\n",
    "\n",
    "output_dir = Path(\"../data_bank_microtasks\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = output_dir / \"microtasks_prototype.json\"\n",
    "\n",
    "with out_path.open(\"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(ml_structure, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved ML structure to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5c78aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programmes: ['Ancient Studies', 'Communication and Information Studies', 'Econometrics and Operations Research', 'History', 'Literature and Society']\n",
      "\n",
      "Programme: Ancient Studies\n",
      " broad questions: 2\n",
      " R questions: 6\n",
      " I questions: 6\n",
      " A questions: 6\n",
      " S questions: 6\n",
      " E questions: 6\n",
      " C questions: 6\n",
      "\n",
      "Example broad question:\n",
      "{'options': {'A': {'riasec': 'A',\n",
      "                   'text': 'Sketch the coin to capture its details and symbols '\n",
      "                           'for further artistic analysis.'},\n",
      "             'B': {'riasec': 'I',\n",
      "                   'text': 'Visit the library to locate academic articles that '\n",
      "                           \"explain the coin's historical period and usage.\"},\n",
      "             'C': {'riasec': 'S',\n",
      "                   'text': 'Contact the museum curator to ask about the '\n",
      "                           'conservation process and physical characteristics '\n",
      "                           'of the coin.'},\n",
      "             'D': {'riasec': 'R',\n",
      "                   'text': 'Analyze the coin’s inscriptions and imagery to '\n",
      "                           'formulate questions about who created it and why.'},\n",
      "             'E': {'riasec': 'E',\n",
      "                   'text': 'Prepare a presentation highlighting why this coin '\n",
      "                           'could be valuable for a public exhibit on ancient '\n",
      "                           'economies.'},\n",
      "             'F': {'riasec': 'C',\n",
      "                   'text': 'Create a detailed bibliography entry and keep '\n",
      "                           'notes on all sources you plan to reference '\n",
      "                           'later.'}},\n",
      " 'question': 'You have just selected an ancient coin from the Allard Pierson '\n",
      "             'collection to start your research. What is your first step to '\n",
      "             'understand its historical context?',\n",
      " 'question_code': 'L_AABAOHW115_1',\n",
      " 'tiny_learn': ['Material culture refers to physical objects made or used by '\n",
      "                'people in the past, which help us learn about history.',\n",
      "                \"Begin by examining the object's features, then find scholarly \"\n",
      "                'sources that discuss similar items.',\n",
      "                \"A common mistake is to rely only on the object's appearance \"\n",
      "                'without considering its historical and cultural background.']}\n",
      "\n",
      "Example R disambiguation question:\n",
      "{'options': {'A': {'riasec': 'R',\n",
      "                   'text': 'Read some related academic articles to gather '\n",
      "                           'interpretations of the coin’s historical meaning.'},\n",
      "             'B': {'riasec': 'I',\n",
      "                   'text': 'Inspect the coin closely and note its physical '\n",
      "                           'details before consulting any written material.'},\n",
      "             'C': {'riasec': 'A',\n",
      "                   'text': 'Start drafting your academic text outline focusing '\n",
      "                           \"on your initial ideas about the coin's \"\n",
      "                           'significance.'}},\n",
      " 'question': 'You have just been assigned a research project on a coin from '\n",
      "             'the ancient collection. What should you do first to start your '\n",
      "             'investigation?',\n",
      " 'question_code': 'L_AABAOHW115_2',\n",
      " 'tiny_learn': ['Material culture consists of physical objects created and '\n",
      "                'used by people in the past.',\n",
      "                'Begin by identifying the object and locating scholarly and '\n",
      "                'primary sources about it.',\n",
      "                'Avoid assuming the meaning of the object without consulting '\n",
      "                'historical context and sources.']}\n"
     ]
    }
   ],
   "source": [
    "with out_path.open(\"r\", encoding=\"utf8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Programmes:\", list(data.keys())[:5])\n",
    "\n",
    "prog_name = next(iter(data.keys()))\n",
    "p = data[prog_name]\n",
    "\n",
    "print(\"\\nProgramme:\", prog_name)\n",
    "print(\" broad questions:\", len(p[\"broad\"]))\n",
    "print(\" R questions:\", len(p[\"R\"]))\n",
    "print(\" I questions:\", len(p[\"I\"]))\n",
    "print(\" A questions:\", len(p[\"A\"]))\n",
    "print(\" S questions:\", len(p[\"S\"]))\n",
    "print(\" E questions:\", len(p[\"E\"]))\n",
    "print(\" C questions:\", len(p[\"C\"]))\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"\\nExample broad question:\")\n",
    "pprint(p[\"broad\"][0])\n",
    "\n",
    "print(\"\\nExample R disambiguation question:\")\n",
    "if p[\"R\"]:\n",
    "    pprint(p[\"R\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e09845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total programmes with microtasks generated: 14\n",
      "Programmes: ['Ancient Studies', 'Communication and Information Studies', 'Econometrics and Operations Research', 'History', 'Literature and Society', 'Philosophy', 'Biomedical Sciences', 'Business Analytics', 'Computer Science', 'Economics and Business Economics', 'International Business Administration', 'Mathematics', 'Media, Art, Design and Architecture', 'Philosophy, Politics and Economics']\n",
      "The number of vectors:  17\n",
      "Programme titles with vectors: ['Ancient Studies', 'Archaeology', 'Artificial Intelligence', 'Biomedical Sciences', 'Business Analytics', 'Communication and Information Studies', 'Computer Science', 'Econometrics and Data Science', 'Econometrics and Operations Research', 'Economics and Business Economics', 'History', 'International Business Administration', 'Literature and Society', 'Mathematics', 'Media, Art, Design and Architecture', 'Philosophy', 'Philosophy, Politics and Economics']\n",
      "Programmes with vectors but no microtasks: {'Archaeology', 'Artificial Intelligence', 'Econometrics and Data Science'}\n"
     ]
    }
   ],
   "source": [
    "# the number and names of the programmes for which microtasks were generated\n",
    "print(\"\\nTotal programmes with microtasks generated:\", len(data))\n",
    "print(\"Programmes:\", list(data.keys()))\n",
    "\n",
    "# open file of programmes vector:\n",
    "programme_vectors_path = \"../data_RIASEC/df_RIASEC_programmes_vectors.csv\"\n",
    "programme_vectors = pd.read_csv(programme_vectors_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "# number of programmes with vectors\n",
    "print(\"The number of vectors: \", len(programme_vectors))\n",
    "print(\"Programme titles with vectors:\", list(programme_vectors[\"programme_title\"].unique()))\n",
    "\n",
    "# diffference between programmes with vectors and programmes with microtasks\n",
    "programmes_with_microtasks = set(data.keys())\n",
    "programmes_with_vectors = set(programme_vectors[\"programme_title\"].unique())\n",
    "programmes_difference = programmes_with_vectors - programmes_with_microtasks\n",
    "print(\"Programmes with vectors but no microtasks:\", programmes_difference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
